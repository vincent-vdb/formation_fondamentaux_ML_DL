{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le Deep Learning\n",
    "\n",
    "- Le machine learning est basé sur l'apprentissage.\n",
    "\n",
    "\n",
    "- Le Deep learning ajoute un nouveau terme : **deep** (profond)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep learning et machine learning\n",
    "\n",
    "### Le deep learning est un sous-domaine spécifique du machine learning \n",
    "\n",
    "- **Définition :** une nouvelle approche de l'apprentissage des représentations à partir de données qui met l'accent sur l'apprentissage de couches successives de représentations de plus en plus significatives. \n",
    "\n",
    "\n",
    "- *Attention* : Le deep learning n’est pas une référence à une forme de compréhension plus profonde. Il représente plutôt cette idée de couches successives de représentations. \n",
    "\n",
    "\n",
    "- Le nombre de couches contribuant à un modèle de données est appelé profondeur du modèle. \n",
    "\n",
    "\n",
    "-  Le deep learning moderne implique souvent des dizaines, voire des centaines, de couches successives de représentations. Celles-ci s’apprennent toutes automatiquement à partir des données d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Le deep learning, c'est quoi ?\n",
    "\n",
    "- Des réseaux de neurones avec plus de couches\n",
    "- Une representation des données non linéaire\n",
    "- Des modèles très flexibles\n",
    "- Données non structurées en entrée et en sortie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Machine learning vs Deep Learning\n",
    "### Machine learning\n",
    "![image](./images/image_ml_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Machine learning vs Deep Learning\n",
    "### Deep learning\n",
    "![image](./images/image_dl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les réseaux de neurones\n",
    "\n",
    "- En deep learning, les représentations en couches sont (presque toujours) apprises au moyen de modèles appelés **réseaux de neurones**, structurés en couches empilées les unes sur les autres. \n",
    "\n",
    "\n",
    "- Le terme réseau de neurones est une référence à la neurobiologie, mais attention les modèles de deep learning ne sont pas des modèles du cerveau. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les principes\n",
    "\n",
    "### À quoi ressemblent les représentations apprises par un algorithme de deep learning ? \n",
    "\n",
    "![image](./images/reseau-de-neurone.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Le réseau transforme l'image numérique en représentations de plus en plus différentes de l'image d'origine et de plus en plus informatives sur le résultat final. \n",
    "\n",
    "Vous pouvez considérer un réseau en profondeur comme une opération de distillation d’informations en plusieurs étapes, dans laquelle l’information passe par des filtres successifs et ressort de plus en plus épurée (c’est-à-dire utile pour certaines tâches).\n",
    "\n",
    "![image](./images/reseau-detail.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Un réseau de neurone pour la reconnaissance d'images\n",
    "\n",
    "http://scs.ryerson.ca/~aharley/vis/conv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Comprendre le fonctionnement du deep learning\n",
    "\n",
    "## Les poids\n",
    "\n",
    "- Ce que fait une couche sur ses données d’entrée est stockée dans les pondérations de la couche. En termes techniques, nous dirions que la transformation mise en œuvre par une couche est paramétrée par ses pondérations. \n",
    "\n",
    "- Apprendre signifie rechercher un ensemble de valeurs pour les pondérations de toutes les couches d'un réseau, de sorte que le réseau mappe correctement les exemples d'entrées sur leurs cibles associées. \n",
    "\n",
    "- Un réseau de neurones profonds peut contenir des dizaines de millions de paramètres. Trouver la valeur correcte pour chacun d'eux peut sembler une tâche ardue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![image](./images/poids-nn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# La fonction de coût/perte (cost/loss function)\n",
    "\n",
    "- Pour contrôler la sortie d'un réseau de neurones, vous devez pouvoir mesurer dans quelle mesure cette sortie est différente de celle que vous attendiez. \n",
    "\n",
    "- C’est le travail de la fonction de perte du réseau, également appelée fonction objectif. \n",
    "\n",
    "- La fonction de perte prend les prédictions du réseau et la vraie cible et calcule un score de distance, rendant compte de la performance du réseau pour cet exemple spécifique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![image](./images/optim-nn.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Fonctionnement\n",
    "\n",
    "- L'astuce fondamentale de l'apprentissage en profondeur consiste à utiliser ce score comme un signal de retour pour ajuster légèrement la valeur des poids, dans un sens qui abaissera le score de perte pour l'exemple actuel. \n",
    "\n",
    "- Cet ajustement est le travail de l'optimiseur, qui met en œuvre ce que l’on appelle l’algorithme de rétropropagation (**Backpropagation**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![image](./images/backprop-nn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Fonctionnement\n",
    "\n",
    "1. Initialement, des valeurs aléatoires sont attribuées aux poids du réseau\n",
    "\n",
    "2. Avec chaque exemple de processus réseau, les poids sont légèrement ajustés et le score de perte diminue \n",
    "\n",
    "Un réseau avec une perte minimale en est un pour lequel les sorties sont aussi proches que possible des cibles. \n",
    "\n",
    "C'est un mécanisme simple qui, une fois mis à l’échelle, finit par ressembler à de la magie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les usages\n",
    "\n",
    "- Bien que l’apprentissage en profondeur soit un sous-domaine assez ancien de l’apprentissage automatique, il n’a pris de l’importance qu'au début des années 2010. \n",
    "\n",
    "\n",
    "- En particulier, l'apprentissage en profondeur a permis les avancées suivantes, toutes dans des domaines historiquement difficiles de l'apprentissage automatique:\n",
    " - Classification des images au niveau presque humain\n",
    " - Reconnaissance de la parole presque humaine\n",
    " - Transcription manuscrite quasi humaine\n",
    " - Traduction automatique améliorée\n",
    " - Conversion texte-parole améliorée\n",
    " - Assistants numériques tels que Google Now et Amazon Alexa\n",
    " - Conduite autonome quasi humaine\n",
    " - Ciblage publicitaire amélioré, utilisé par Google, Baidu et Bing\n",
    " - Résultats de recherche améliorés sur le Web\n",
    " - Capacité à répondre à des questions en langage naturel\n",
    " - ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  Paroles vers texte\n",
    "\n",
    "![image](./images/speech.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Traitement de la vision par ordinateur\n",
    "\n",
    "![image](./images/vision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# D'autre cas de vision par ordinateur\n",
    "\n",
    "![image](./images/vision2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# NLP\n",
    "![image](./images/nlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# NLP\n",
    "\n",
    "![image](./images/nlp2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Vision + NLP\n",
    "\n",
    "![image](./images/nlp_vision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Translation de styles d'images\n",
    "Style transfer : https://tenso.rs/demos/fast-neural-style/\n",
    "\n",
    "![image](./images/vision_translation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Modèles génératifs\n",
    "\n",
    "![image](./images/nvidia_celeb.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dernières avancées sur les modèles génératifs\n",
    "\n",
    "![image](./images/WaveNet.gif)\n",
    "\n",
    "GAN lab: https://poloclub.github.io/ganlab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Quelques expérimentations de deep learning\n",
    "\n",
    "https://trekhleb.dev/machine-learning-experiments/#/\n",
    "\n",
    "Testez les expérimentations qui vous intéressent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Retour aux réseaux de neurones\n",
    "\n",
    "- Vers 2010, bien que la communauté scientifique ait presque complètement fui les réseaux de neurones, plusieurs personnes travaillant encore sur les réseaux de neurones ont commencé à faire des percées importantes : \n",
    " \n",
    " - les groupes de Geoffrey Hinton de l'Université de Toronto, \n",
    " - Yoshua Bengio de l'Université de Montréal., \n",
    " - Yann LeCun à l’Université de New York et IDSIA en Suisse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- Les dates clés :\n",
    " \n",
    " - 2011 : Dan Ciresan de l'IDSIA a commencé à remporter des concours universitaires de classification d'images avec des réseaux de neurones profonds formés par GPU\n",
    " - 2012 : groupe Hinton dans le défi annuel de la classification des images à grande échelle ImageNet. Classer les images couleur haute résolution en 1 000 catégories différentes après une formation sur 1,4 million d’images. \n",
    " - Depuis 2012, les réseaux de neurones convolutifs (convnets/CNNs) sont devenus l'algorithme de référence pour toutes les tâches de vision par ordinateur.\n",
    " - Parallèlement, le deep learning a remplacé les SVM et les arbres de décision dans un large éventail d'applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Un neurone : le perceptron\n",
    "\n",
    "![](images/Perceptron_forward.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Le réseau de neurones classique : Multi Layer Perceptron\n",
    "\n",
    "![](images/MLP_with_activations.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Les fonctions d'activation\n",
    "\n",
    "![](images/activation_purpose.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Les principales fonctions d'activation\n",
    "\n",
    "- sigmoid : $ sigmoid(x) = \\frac{1}{1+e^{-x}} $\n",
    "- tangente hyperbolique : $ tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $\n",
    "- ReLU (Rectifier Linear Unit) : $ relu(x) = max(0, x) $\n",
    "- Softmax : en dernière couche d'une classification multiclasse\n",
    "- Linéaire : en dernière couche d'une régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Les réseaux de neurones\n",
    "\n",
    "Essayez de manipuler les couches de ce réseau de neurones :\n",
    "\n",
    "https://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Les hyperparamètres en deep learning\n",
    "\n",
    "- L'architecture : nombre de couches, de neurones par couche\n",
    "- Les fonctions d'activation\n",
    "- Le learning rate\n",
    "![](images/lr_epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Le nombre d'epochs et le batch size\n",
    "![](images/minibatch_vs_batch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- L'optimisation (SGB, Adam, RMSprop...)\n",
    "![](images/optimizers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Early stopping\n",
    "![](images/mnist_train_and_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- ... Et bien d'autres\n",
    "\n",
    "Ce qui peut rendre les réseaux de neurones difficiles à exploiter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Qu'est-ce qui rend l'apprentissage en profondeur différent ?\n",
    "\n",
    "- De meilleures performances sur de nombreux problèmes : la traduction, la reconnaissance d'images, la reconnaissance de paroles...\n",
    "\n",
    "- Il facilite également la résolution de problèmes, car il automatise parfois complètement ce qui était auparavant l'étape la plus cruciale d'un processus d'apprentissage automatique : le **feature engineering**. C'est surtout vrai pour les données non structurées.\n",
    "\n",
    "- Cela a grandement simplifié les flux de travail d'apprentissage automatique, remplaçant des pipelines sophistiqués à plusieurs niveaux par un modèle unique, d'apprentissage en profondeur, de bout en bout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pourquoi l'apprentissage en profondeur ? Pourquoi maintenant ?\n",
    "\n",
    "- Les deux idées clés de l'apprentissage en profondeur pour la vision par ordinateur - **réseaux de neurones convolutifs et rétropropagation** - étaient déjà bien comprises en 1989. \n",
    "\n",
    "- L'algorithme de la mémoire à court terme (LSTM), qui est fondamental pour l'apprentissage en profondeur pour la série temporelle, a été développé en 1997 et a peu changé depuis. \n",
    "\n",
    "\n",
    "En général, trois forces techniques sont à l'origine des progrès de l'apprentissage automatique:\n",
    "- Matériel\n",
    "- Jeux de données et benchmarks\n",
    "- Avancées algorithmiques\n",
    "\n",
    "Parce que le domaine est guidé par des résultats expérimentaux plutôt que par la théorie, les progrès algorithmiques ne sont possibles que lorsque des données et du matériel appropriés sont disponibles pour essayer de nouvelles idées (ou redimensionner des idées anciennes, comme cela est souvent le cas). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Matériel\n",
    "\n",
    "- Entre 1990 et 2010, les processeurs standard ont été multipliés par 5 000 environ.\n",
    "\n",
    "- Au cours des années 2000, des sociétés telles que NVIDIA et AMD ont investi des milliards de dollars dans le développement de puces massivement parallèles rapides (unités de traitement graphique GPU) pour alimenter les graphismes de jeux vidéo.\n",
    "\n",
    "- Cet investissement a profité à la communauté scientifique lorsque, en 2007, NVIDIA a lancé CUDA, une interface de programmation pour sa gamme de GPU. \n",
    "\n",
    "- Un petit nombre de GPU ont commencé à remplacer des grappes massives de processeurs dans diverses applications hautement parallélisables.\n",
    "\n",
    "- Les réseaux neuronaux profonds, constitués principalement de nombreuses multiplications de petites matrices, sont également hautement parallélisables; et vers 2011, certains chercheurs ont commencé à écrire des implémentations CUDA de réseaux de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les données\n",
    "\n",
    "- En ce qui concerne les données, en plus des progrès exponentiels du matériel de stockage au cours des 20 dernières années, le jeu a été révolutionné grâce à Internet, ce qui permet de collecter et de distribuer de très grands ensembles de données pour l'apprentissage automatique. \n",
    "\n",
    "\n",
    "- Aujourd’hui, les grandes entreprises travaillent avec des jeux de données d’image, des jeux de données vidéo et des jeux de données en langage naturel qui n’auraient pas pu être collectés sans Internet. \n",
    "\n",
    "- Les tags d'image générés par les utilisateurs sur Flickr, par exemple, ont constitué un trésor de données pour la vision par ordinateur. Il en va de même pour les vidéos YouTube. Et Wikipedia est un ensemble de données clé pour le traitement en langage naturel.\n",
    "\n",
    "- Si un jeu de données a joué un rôle catalyseur dans l’apprentissage en profondeur, c’est le jeu de données ImageNet, constitué de 1,4 million d’images annotées à la main avec 1 000 catégories d’images (1 catégorie par image). Mais ce qui rend ImageNet spécial, ce n’est pas seulement sa grande taille, mais aussi la compétition annuelle qui lui est associée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Algorithmes\n",
    "\n",
    "La question clé était celle de la propagation du gradient à travers des piles de couches profondes. Le signal de retour utilisé pour former les réseaux de neurones disparaîtrait avec l’augmentation du nombre de couches.\n",
    "\n",
    "Cela a changé vers 2009-2010 avec l'avènement de plusieurs améliorations algorithmiques simples mais importantes qui ont permis une meilleure propagation du gradient:\n",
    "\n",
    "- De meilleures fonctions d'activation, non saturantes\n",
    "- Amélioration des schémas d'initialisation du poids\n",
    "- De meilleurs schémas d'optimisation, tels que RMSProp et Adam\n",
    "\n",
    "Enfin, en 2014, 2015 et 2016, des méthodes encore plus avancées d'aide à la propagation du gradient ont été découvertes, telles que la normalisation par lots (batch normalization), les connexions résiduelles (residual network), le dropout... Aujourd'hui, nous pouvons former à partir de zéro des modèles d'une profondeur de milliers de couches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Format des données pour le deep learning\n",
    "\n",
    "- Les données sont stockées dans des tenseurs (équivalent des arrays de Numpy)\n",
    "\n",
    "\n",
    "- Les données que vous manipulerez tomberont presque toujours dans l’une des catégories suivantes:\n",
    "\n",
    "  - Données vectorielles : Tenseurs de forme 2D\n",
    "  - Données de série temporelle ou données de séquence : tenseurs de forme 3D\n",
    "  - Images : Tenseurs de forme 4D\n",
    "  - Vidéo : Tenseurs de forme 5D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Données vectorielles\n",
    "C'est le cas le plus fréquent. Dans un tel ensemble de données, chaque point de données peut être codé en tant que vecteur.\n",
    "\n",
    "Prenons deux exemples:\n",
    "\n",
    "- Un ensemble de données actuarielles sur les personnes, qui prend en compte l’âge, le code postal et le revenu de chaque personne. Chaque personne peut être caractérisée comme un vecteur de 3 valeurs. Ainsi, un ensemble de données complet de 100 000 personnes peut être stocké dans un tenseur 2D de forme (100000, 3).\n",
    "\n",
    "\n",
    "- Un ensemble de données de documents texte, où nous représentons chaque document en comptant le nombre de fois que chaque mot y figure (sur un dictionnaire de 20 000 mots communs). Chaque document peut être codé sous forme de vecteur de 20 000 valeurs (un décompte par mot dans le dictionnaire). Ainsi, un jeu de données complet de 500 documents peut être stocké dans un tenseur de forme (500, 20000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Données de séries chronologiques ou données de séquence\n",
    "\n",
    "Chaque fois que le temps compte dans vos données, il est logique de le stocker dans un tenseur 3D avec un axe de temps explicite. \n",
    "\n",
    "L'axe des temps est toujours le deuxième axe (axe d'indice 1), par convention. Voyons quelques exemples:\n",
    "\n",
    "- Un ensemble de données sur les cours des actions. À chaque minute, nous enregistrons le prix actuel, le prix le plus élevé de la dernière minute et le prix le plus bas de la dernière minute. Ainsi, chaque minute est codée sous forme de vecteur 3D, une journée entière de négociation est codée sous la forme d’un tenseur 2D de forme (390, 3) (il ya 390 minutes dans une journée de négociation) et vous pouvez stocker 250 jours de données. un tenseur de forme 3D (250, 390, 3).\n",
    "\n",
    "- Un ensemble de données de tweets, dans lequel nous encodons chaque tweet sous forme d'une séquence de 280 caractères sur un alphabet de 128 caractères uniques. Dans ce paramètre, chaque caractère peut être codé sous forme de vecteur binaire de taille 128 (vecteur de tous les zéros, à l’exception d’une entrée 1 de l’index correspondant au caractère). Chaque tweet peut ensuite être codé comme un tenseur de forme 2D (280, 128) et un ensemble de données de 1 million de tweets peut être stocké dans un tenseur de forme (1000000, 280, 128)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![image](./images/timeseries-tensor.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Données d'image\n",
    "\n",
    "Les images ont généralement trois dimensions: hauteur, largeur et profondeur de couleur. Les tenseurs d'image sont toujours, par convention, 3D, avec un canal de couleur unidimensionnel pour les images en niveaux de gris. \n",
    "\n",
    "Un lot de 128 images en niveaux de gris de taille 256 × 256 pourrait ainsi être stocké dans un tenseur de forme (128, 256, 256, 1) et un lot de 128 images en couleurs pourrait être stocké dans un tenseur de forme (128, 256, 256, 3)\n",
    "\n",
    "![image](./images/image-tensor.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Vidéo\n",
    "\n",
    "Les données vidéo sont l’un des rares types de données réelles pour lesquelles vous aurez besoin de tenseurs 5D. \n",
    "\n",
    "Une vidéo peut être comprise comme une séquence d'images, chaque image étant une image couleur. Comme chaque image peut être stockée dans un tenseur 3D (hauteur, largeur, profondeur de couleur), une séquence d'images peut être stockée dans un tenseur 4D (images, hauteur, largeur, profondeur de couleur) et ainsi stocker un lot de vidéos différentes. un tenseur de forme 5D.\n",
    "\n",
    "Par exemple, un clip vidéo YouTube de 60 secondes, 144 × 256, échantillonné à 4 images par seconde comporterait 240 images. Un lot de quatre de ces clips vidéo serait stocké dans un tenseur de forme (4, 240, 144, 256, 3). C’est un total de 106 168 320 valeurs! \n",
    "\n",
    "Si le type de tenseur était float32, chaque valeur serait alors stockée sur 32 bits, de sorte que le tenseur représenterait 405 Mo. Lourd! \n",
    "\n",
    "Les vidéos que vous rencontrez dans la vie réelle sont beaucoup plus légères, car elles ne sont pas stockées dans float32, et elles sont généralement compressées par un facteur important (tel que le format MPEG)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le framework TensorFlow - les technologies Google\n",
    "\n",
    "- TensorFlow est un framework d’apprentissage en profondeur pour Python qui offre un moyen pratique de définir et de former presque tous les types de modèles d’apprentissage en profondeur. Keras a été initialement développé pour les chercheurs, dans le but de permettre une expérimentation rapide.\n",
    "\n",
    "  - Keras présente les caractéristiques principales suivantes:\n",
    "\n",
    "  - Il permet au même code de s'exécuter de manière transparente sur le processeur ou le processeur graphique.\n",
    " \n",
    "  - Son API conviviale facilite le prototypage rapide de modèles d'apprentissage en profondeur.\n",
    " \n",
    "  - Il prend en charge les réseaux de convolution, les réseaux récurrents, et toute combinaison des deux.\n",
    " \n",
    "  - Il prend en charge des architectures de réseau arbitraires: modèles à entrées multiples ou à sorties multiples, partage de couche, partage de modèle, etc. Cela signifie que Keras est approprié pour construire essentiellement n'importe quel modèle d'apprentissage en profondeur.\n",
    " \n",
    "  - Keras est distribué sous licence MIT, ce qui signifie qu'il peut être utilisé librement dans des projets commerciaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Processus de développement d'un modèle de deep learning avec Keras\n",
    "\n",
    "1. Définissez vos données d’entraînement: tenseur d’entrée et tenseur de cible.\n",
    "\n",
    "2. Définissez un réseau de couches (ou un modèle) qui mappe vos entrées sur vos cibles.\n",
    "\n",
    "3. Configurez le processus d'apprentissage en choisissant une fonction de perte, un optimiseur et certaines mesures à surveiller.\n",
    "\n",
    "4. Itérez sur vos données d'entraînement en appelant la méthode fit () de votre modèle.\n",
    "\n",
    "\n",
    "Il existe deux manières de définir un modèle: en utilisant la classe `Sequential` ou l'API fonctionnelle (pour les graphes acycliques, ce qui vous permet de construire des architectures complètement arbitraires). Nous utiliserons la première approche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Passage au Notebook sur le deep learning"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

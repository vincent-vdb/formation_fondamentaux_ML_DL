{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L’apprentissage non supervisé\n",
    "\n",
    "## Implémentation d’une méthode de clustering avec Python\n",
    "\n",
    "Dans le cas d’un clustering les données consiste en un bloc de variables x\n",
    "desquelles on va extraire des groupes d’observations.\n",
    "\n",
    "Nous allons appliquer les k-means directement sur les données. Les k-means\n",
    "(k-moyennes) sont donc un algorithme d’apprentissage non supervisé permettant\n",
    "de construire des classes d’observations à partir d’un jeu de données de grande\n",
    "dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Préparation des données\n",
    "\n",
    "Les données que nous utilisons sont des données sur les communes d’Île-de-\n",
    "France et leur caractéristiques socio-démographiques. \n",
    "\n",
    "Notre objectif est ici de comprendre s’il existe des classes de communes ayant des caractéristiques proches.\n",
    "On obtiendra ainsi une typologie des communes d’Île-de-France et on pourra représenter\n",
    "ces groupes sur une carte.\n",
    "\n",
    "Nous allons préparer ces données qui sont disponibles sur le site du livre. Une\n",
    "description est disponible au début du chapitre 4.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# on récupère le fichier csv\n",
    "data=pd.read_csv(\"./data/base-dpt.csv\",sep=\";\")\n",
    "# on enlève des variables avec trop de données manquantes\n",
    "data.drop([\"PIMP14\",\"TP6014\"],axis=1,inplace=True)\n",
    "# on enlève les observations avec des données manquantes\n",
    "data.dropna(inplace=True)\n",
    "# on extrait dans un DataFrame la position géographique des comunes\n",
    "position=pd.DataFrame(data[\"geo_point_2d\"])\n",
    "# on crée une colonne longitude en prenant la première partie\n",
    "# de la colonne geo_point_2\n",
    "position[\"longitude\"]=pd.to_numeric(position[\"geo_point_2d\"].str.split(',')\\\n",
    "                                    .str.get(0))\n",
    "# on fait la même chose pour la latitude\n",
    "position[\"latitude\"]=pd.to_numeric(position[\"geo_point_2d\"].str.split(',')\\\n",
    "                                   .str.get(1))\n",
    "# finalement, on sélectionne uniquement les données numériques\n",
    "# pour faire notre K-means et on enlève trois variables inutiles\n",
    "x=data.select_dtypes(np.number).drop([\"CODGEO\",\"REG\",\"DEP\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validation du modèle et choix du nombre de classes\n",
    "Dans le cas du clustering, il est très difficile de valider le modèle avec des indicateurs\n",
    "statistiques. En effet, on ne peut pas tester la qualité prédictive. Nous allons\n",
    "essayer de faire en sorte d’obtenir des classes les plus homogènes possibles et de\n",
    "minimiser l’inertie. \n",
    "\n",
    "Afin de choisir le nombre de classe à utiliser on peut utiliser un\n",
    "graphique. Elle représente l’inertie par nombre de classes. On recherche un coude\n",
    "dans cette courbe pour décider le nombre à retenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# on crée une liste dans laquelle on stocke les inerties\n",
    "inerties=[]\n",
    "# on fait une boucle de 2 à 9 pour tester toutes ces possibiliéts\n",
    "for k in range(2, 10):\n",
    "    # pour chaque k, on crée un modèle et on l’ajuste\n",
    "    kmeans=KMeans(n_clusters=k)\n",
    "    kmeans.fit(x)\n",
    "    # on stocke l’inertie associée\n",
    "    inerties.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# on représente le graphique\n",
    "fig=plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(2, 10), inerties)\n",
    "plt.xlabel(\"Nombre de clusters\")\n",
    "plt.ylabel(\"Inertie\")\n",
    "plt.title('Inertie vs nombre de classes')\n",
    "plt.savefig(\"./elbow.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application des k-means\n",
    "Pour appliquer les k-means sur nos données, on utilisera :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "modele_km = KMeans(n_clusters=4)\n",
    "modele_km.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# on stocke les classes d’appartenance dans classes\n",
    "classes=modele_km.labels_\n",
    "# on crée un DataFrame avec le nombre d’individus par calsse\n",
    "count=pd.DataFrame(np.unique(classes,return_counts=True)[1],\n",
    "columns=[\"Nombre d’individus\"])\n",
    "# on stocke les centres des classes dans un DataFrame\n",
    "centres=pd.DataFrame(modele_km.cluster_centers_,columns=x.columns)\n",
    "# on affiche le DataFrame avec les deux informations\n",
    "pd.set_option('precision',2)\n",
    "print(pd.concat([count,pd.DataFrame(centres,columns=x.columns)],axis=1).T)\n",
    "pd.reset_option('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# on crée une figure\n",
    "plt.figure(figsize=(10,6))\n",
    "# on fait une boucle sur les classes en définissant des marqueurs par classe\n",
    "markers=[\"+\",\"s\",\"^\",\"v\"]\n",
    "for val, mark in zip(np.unique(classes),markers):\n",
    "    plt.scatter(position[\"latitude\"][classes==val],\n",
    "                position[\"longitude\"][classes==val], marker=mark,\n",
    "                label=\"classe% i\"%(val))\n",
    "plt.title(\"Représentation des classes sur la région Ile-de-France\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./idf2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image](./images/idf2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On voit que les quatre classes se répartissent très bien sur l’Ile-de-France avec :\n",
    "- Classe 0 : petites communes éloignées de Paris\n",
    "- Classe 1 : grandes communes de la petite ceinture\n",
    "- Classe 2 : arrondissements extérieurs de Paris (12 à 20)\n",
    "- Classe 3 : communes moyennes moins proches de Paris\n",
    "\n",
    "On pourrait bien entendu ajouter un fond de carte comme nous l’avons fait dans\n",
    "le chapitre 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Traitement d'image avec les Kmeans\n",
    "\n",
    "On veut changer le nombre de couleur d'une photo de la tour Eiffel avec les K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tour_eiffel = plt.imread(\"./Data/tour-eiffel.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(tour_eiffel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On commence par empiler les pixels dans un format avec 2 dimension (3 colonnes et autant de lignes que de pixels)\n",
    "\n",
    "**Indice :** On utilise `.reshape()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tour_eiffel.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On applique les k-means sur l'array obtenu avec n_clusters égal au nombre de couleurs voulu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ny=KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ny.fit(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On obtient les labels de chaque pixel (la classe) et la couleur centrale de chaque classe.\n",
    "\n",
    "On utilise`.labels_` et `.cluster_centers_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label= kmeans_ny.labels_\n",
    "centers = kmeans_ny.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers[label].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On utilise le code \n",
    "```\n",
    "new_image = centers[label].reshape(tour_eiffel.shape)\n",
    "```\n",
    "pour reconstruire l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = centers[label].reshape(tour_eiffel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les méthodes de réduction de dimension\n",
    "\n",
    "Parmi les algorithmes non supervisés, on inclut souvent des méthodes qui permettent de réduire le nombre de dimensions de vos données. Nous allons présenter\n",
    "l’utilisation de trois d’entre elles : l’analyse en composantes principales et deux\n",
    "méthodes non linéaires.\n",
    "\n",
    "Les méthodes de réduction de dimensions se divisent en deux familles : les\n",
    "méthodes linéaires et les méthodes non linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Méthodes linéaires\n",
    "Il s’agit de méthodes d’analyse de données souvent bien connues. On pourra citer :\n",
    "\n",
    "- l’analyse en composantes principales (ACP/PCA)\n",
    "- l’analyse en composantes indépendantes\n",
    "- la décomposition en valeurs singulières\n",
    "- l’analyse factorielle\n",
    "- les analyses multi-tableaux\n",
    "\n",
    "Et pour des données qualitatives :\n",
    "   \n",
    "- l’analyse des correspondances multiples\n",
    "\n",
    "Scikit-Learn possède de nombreuses approches mais nous allons nous concentrer sur une application de l’analyse en composantes principales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application de l'ACP\n",
    "Nous utilisons une base de données d’images : celle du jeu de données Fashion-\n",
    "MNIST qui rassemble des photographies de vêtements (un vêtement par image).\n",
    "Ces données sont directement disponibles dans le package Keras. Nous allons utiliser l’ACP pour réduire la complexité de ces images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# on récupère les données dans 4 arrays\n",
    "(train_img, train_lbl), (test_img, test_lbl)=fashion_mnist.load_data()\n",
    "# ce jeu de données d’apprentissage est composé de 600000 images\n",
    "# ayant 28 x 28 pixels en noir et blanc\n",
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# l’image 801 a le label 9: chaussure\n",
    "train_lbl[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_img[150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nous avons donc récupéré des images de taille 28 par 28 qui sont stockées dans\n",
    "un array avec une image par ligne.\n",
    "\n",
    "L’objectif est de réduire le nombre d’informations nécessaires à l’apprentissage de ces images en vue d’appliquer un modèle prédictif. Nous allons voir comment simplifier ces images en utilisant toutes les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# on passe les images en deux dimensions\n",
    "img_acp=train_img.reshape(train_img.shape[0],-1)\n",
    "\n",
    "# on crée un modèle d’ACP\n",
    "pca=PCA(n_components=.80)\n",
    "\n",
    "# on réduit le nombre de dimensions avec l’ACP\n",
    "donnees_reduites=pca.fit_transform(img_acp)\n",
    "\n",
    "# Pour capturer 80% de l’information, on utiliser 43 des 784 composantes\n",
    "# on projette les données réduites dans l’espace d’origine\n",
    "projection=pca.inverse_transform(donnees_reduites)\n",
    "\n",
    "donnees_reduites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# on affiche les résultats\n",
    "plt.figure(figsize=(8,4));\n",
    "# image initale\n",
    "plt.subplot(1, 2, 1);\n",
    "plt.imshow(img_acp[150].reshape(28,28))\n",
    "plt.xlabel('%i composantes'%(img_acp.shape[1]))\n",
    "plt.title('Image initiale');\n",
    "# image basée sur l’ACP\n",
    "plt.subplot(1, 2, 2);\n",
    "plt.imshow(projection[150].reshape(28, 28))\n",
    "plt.xlabel('%i composantes' %(donnees_reduites.shape[1]))\n",
    "plt.title('%s de variance expliquée'%(str(pca.n_components*100)+\"%\"))\n",
    "plt.savefig(\"transfo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aller plus loin\n",
    "\n",
    "De nombreuses autres méthodes de machine learning non supervisé sont disponibles. La documentation de scikit-learn vous aidera à en avoir un aperçu très lare :\n",
    "    \n",
    "- Clustering : \n",
    "\n",
    "http://scikit-learn.org/stable/modules/clustering.html#clustering\n",
    "\n",
    "\n",
    "- Réduction de dimension : \n",
    "\n",
    "http://scikit-learn.org/stable/modules/decomposition.html#decompositions"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
